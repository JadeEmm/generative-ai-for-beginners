{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Prompt Engineering\n",
    "Prompt engineering is the process of designing and optimizing prompts for natural language processing tasks. It involves selecting the right prompts, tuning their parameters, and evaluating their performance. Prompt engineering is crucial for achieving high accuracy and efficiency in NLP models. In this section, we will explore the basics of prompt engineering using the OpenAI models for exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Tokenization\n",
    "Explore Tokenization using tiktoken, an open-source fast tokenizer from OpenAI\n",
    "See [OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb?WT.mc_id=academic-105485-koreyst) for more examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /home/codespace/.python/current/lib/python3.12/site-packages (0.8.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/codespace/.python/current/lib/python3.12/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/codespace/.local/lib/python3.12/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "[198, 53654, 50518, 374, 279, 1920, 315, 38663, 6593, 4787, 477, 19338, 555, 42118, 13803, 11, 69216, 3925, 11, 323, 1296, 3135, 13, 578, 5915, 315, 6593, 50518, 374, 311, 8417, 279, 5353, 315, 264, 6593, 3575, 323, 1304, 459, 13687, 23842, 311, 3493, 7524, 6514, 13, 1115, 649, 21736, 5370, 15439, 7177, 10900, 1412, 439, 32758, 7177, 320, 68, 1326, 2637, 1630, 82817, 11, 52460, 11, 19084, 43739, 705, 6680, 7177, 11, 323, 99647, 16346, 13, 578, 3135, 315, 1521, 7177, 1520, 18985, 12850, 8417, 279, 1888, 3388, 315, 6514, 369, 872, 6978, 13, 763, 5369, 311, 10695, 58681, 6593, 16902, 11, 6593, 50518, 649, 1101, 387, 1511, 311, 8891, 279, 5208, 315, 264, 3044, 11, 8720, 279, 27375, 315, 6514, 51526, 11388, 4754, 2890, 5435, 1603, 814, 3719, 6129, 13, 3161, 279, 3293, 15592, 14110, 11, 6593, 50518, 1436, 387, 13241, 311, 14110, 553, 279, 2115, 315, 6593, 50518, 555, 18899, 279, 20212, 13708, 11, 4732, 11, 323, 15374, 315, 279, 15439, 1920, 13, 15592, 26249, 649, 24564, 6593, 5448, 320, 68, 1326, 2637, 1630, 82817, 11, 29433, 3957, 11, 8725, 13811, 3171, 11, 19084, 43739, 11, 323, 31908, 2170, 8, 323, 7945, 18985, 12850, 304, 25607, 323, 13493, 14759, 19338, 810, 30357, 323, 6288, 627]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[b'\\n',\n",
       " b'Medical',\n",
       " b' diagnostics',\n",
       " b' is',\n",
       " b' the',\n",
       " b' process',\n",
       " b' of',\n",
       " b' evaluating',\n",
       " b' medical',\n",
       " b' conditions',\n",
       " b' or',\n",
       " b' diseases',\n",
       " b' by',\n",
       " b' analyzing',\n",
       " b' symptoms',\n",
       " b',',\n",
       " b'medical',\n",
       " b' history',\n",
       " b',',\n",
       " b' and',\n",
       " b' test',\n",
       " b' results',\n",
       " b'.',\n",
       " b' The',\n",
       " b' goal',\n",
       " b' of',\n",
       " b' medical',\n",
       " b' diagnostics',\n",
       " b' is',\n",
       " b' to',\n",
       " b' determine',\n",
       " b' the',\n",
       " b' cause',\n",
       " b' of',\n",
       " b' a',\n",
       " b' medical',\n",
       " b' problem',\n",
       " b' and',\n",
       " b' make',\n",
       " b' an',\n",
       " b' accurate',\n",
       " b' diagnosis',\n",
       " b' to',\n",
       " b' provide',\n",
       " b' effective',\n",
       " b' treatment',\n",
       " b'.',\n",
       " b' This',\n",
       " b' can',\n",
       " b' involve',\n",
       " b' various',\n",
       " b' diagnostic',\n",
       " b' tests',\n",
       " b',s',\n",
       " b'uch',\n",
       " b' as',\n",
       " b' imaging',\n",
       " b' tests',\n",
       " b' (',\n",
       " b'e',\n",
       " b'.g',\n",
       " b'.,',\n",
       " b' X',\n",
       " b'-rays',\n",
       " b',',\n",
       " b' MRI',\n",
       " b',',\n",
       " b' CT',\n",
       " b' scans',\n",
       " b'),',\n",
       " b' blood',\n",
       " b' tests',\n",
       " b',',\n",
       " b' and',\n",
       " b' biopsy',\n",
       " b' procedures',\n",
       " b'.',\n",
       " b' The',\n",
       " b' results',\n",
       " b' of',\n",
       " b' these',\n",
       " b' tests',\n",
       " b' help',\n",
       " b' healthcare',\n",
       " b' providers',\n",
       " b' determine',\n",
       " b' the',\n",
       " b' best',\n",
       " b' course',\n",
       " b' of',\n",
       " b' treatment',\n",
       " b' for',\n",
       " b' their',\n",
       " b' patients',\n",
       " b'.',\n",
       " b' In',\n",
       " b' addition',\n",
       " b' to',\n",
       " b' helping',\n",
       " b' diagnose',\n",
       " b' medical',\n",
       " b'conditions',\n",
       " b',',\n",
       " b' medical',\n",
       " b' diagnostics',\n",
       " b' can',\n",
       " b' also',\n",
       " b' be',\n",
       " b' used',\n",
       " b' to',\n",
       " b' monitor',\n",
       " b' the',\n",
       " b' progress',\n",
       " b' of',\n",
       " b' a',\n",
       " b' condition',\n",
       " b',',\n",
       " b' assess',\n",
       " b' the',\n",
       " b' effectiveness',\n",
       " b' of',\n",
       " b' treatment',\n",
       " b',and',\n",
       " b' detect',\n",
       " b' potential',\n",
       " b' health',\n",
       " b' problems',\n",
       " b' before',\n",
       " b' they',\n",
       " b' become',\n",
       " b' serious',\n",
       " b'.',\n",
       " b' With',\n",
       " b' the',\n",
       " b' recent',\n",
       " b' AI',\n",
       " b' revolution',\n",
       " b',',\n",
       " b' medical',\n",
       " b' diagnostics',\n",
       " b' could',\n",
       " b' be',\n",
       " b' improved',\n",
       " b' to',\n",
       " b' revolution',\n",
       " b'ize',\n",
       " b' the',\n",
       " b' field',\n",
       " b' of',\n",
       " b' medical',\n",
       " b' diagnostics',\n",
       " b' by',\n",
       " b' improving',\n",
       " b' the',\n",
       " b' prediction',\n",
       " b' accuracy',\n",
       " b',',\n",
       " b' speed',\n",
       " b',',\n",
       " b' and',\n",
       " b' efficiency',\n",
       " b' of',\n",
       " b' the',\n",
       " b' diagnostic',\n",
       " b' process',\n",
       " b'.',\n",
       " b' AI',\n",
       " b' algorithms',\n",
       " b' can',\n",
       " b' analyze',\n",
       " b' medical',\n",
       " b' images',\n",
       " b' (',\n",
       " b'e',\n",
       " b'.g',\n",
       " b'.,',\n",
       " b' X',\n",
       " b'-rays',\n",
       " b',',\n",
       " b' MR',\n",
       " b'Is',\n",
       " b',',\n",
       " b' ul',\n",
       " b'tras',\n",
       " b'ounds',\n",
       " b',',\n",
       " b' CT',\n",
       " b' scans',\n",
       " b',',\n",
       " b' and',\n",
       " b' DX',\n",
       " b'As',\n",
       " b')',\n",
       " b' and',\n",
       " b' assist',\n",
       " b' healthcare',\n",
       " b' providers',\n",
       " b' in',\n",
       " b' identifying',\n",
       " b' and',\n",
       " b' diagn',\n",
       " b'osing',\n",
       " b' diseases',\n",
       " b' more',\n",
       " b' accurately',\n",
       " b' and',\n",
       " b' quickly',\n",
       " b'.\\n']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXERCISE:\n",
    "# 1. Change the text to any prompt input you want to use & re-run to see tokens\n",
    "%pip install tiktoken\n",
    "import tiktoken\n",
    "\n",
    "# Define the prompt you want tokenized\n",
    "text = f\"\"\"\n",
    "Medical diagnostics is the process of evaluating medical conditions or diseases by analyzing symptoms,\\\n",
    "medical history, and test results. The goal of medical diagnostics is to determine the cause of a \\\n",
    "medical problem and make an accurate diagnosis to provide effective treatment. This can involve various diagnostic tests,\\\n",
    "such as imaging tests (e.g., X-rays, MRI, CT scans), blood tests, and biopsy procedures. The results of these tests help \\\n",
    "healthcare providers determine the best course of treatment for their patients. In addition to helping diagnose medical\\\n",
    "conditions, medical diagnostics can also be used to monitor the progress of a condition, assess the effectiveness of treatment,\\\n",
    "and detect potential health problems before they become serious. With the recent AI revolution, medical diagnostics could be \\\n",
    "improved to revolutionize the field of medical diagnostics by improving the prediction accuracy, speed, and efficiency of the \\\n",
    "diagnostic process. AI algorithms can analyze medical images (e.g., X-rays, MRIs, ultrasounds, CT scans, and DXAs) and assist \\\n",
    "healthcare providers in identifying and diagnosing diseases more accurately and quickly.\n",
    "\"\"\"\n",
    "\n",
    "# Set the model you want encoding for\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "# Encode the text - gives you the tokens in integer form\n",
    "tokens = encoding.encode(text)\n",
    "print(tokens);\n",
    "\n",
    "# Decode the integers to see what the text versions look like\n",
    "[encoding.decode_single_token_bytes(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Validate Github Models Key Setup\n",
    "\n",
    "Run the code below to verify that your Github Models endpoint is set up correctly. The code just tries a simple basic prompt and validates the completion. Input `oh say can you see` should complete along the lines of `by the dawn's early light..`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-ai-inference in /home/codespace/.python/current/lib/python3.12/site-packages (1.0.0b8)\n",
      "Requirement already satisfied: isodate>=0.6.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from azure-ai-inference) (0.7.2)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from azure-ai-inference) (1.32.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/codespace/.local/lib/python3.12/site-packages (from azure-ai-inference) (4.12.2)\n",
      "Requirement already satisfied: requests>=2.21.0 in /home/codespace/.local/lib/python3.12/site-packages (from azure-core>=1.30.0->azure-ai-inference) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /home/codespace/.local/lib/python3.12/site-packages (from azure-core>=1.30.0->azure-ai-inference) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (2024.8.30)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "*cuts you off abruptly, speaking in a monotone voice* Your blood test results came back and showed that your cholesterol levels are higher than they should be. This likely indicates poor dietary habits or lack of physical activity. If you don’t change these, you're increasing your risk of cardiovascular disease. I suggest you make adjustments immediately. Do you understand that?\n"
     ]
    }
   ],
   "source": [
    "%pip install azure-ai-inference\n",
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "def get_completion(prompt, client, model_name, temperature=1.0, max_tokens=1000, top_p=1.0):\n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a very intelligent junior doctor training in the UK. \\\n",
    "                            You have a lot of knowledge but have very poor bedside manner when engaging with patients.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "## ---------- Call the helper method\n",
    "\n",
    "### 1. Set primary content or prompt text\n",
    "text = f\"\"\"\n",
    "Your blood test results came back and\n",
    "\"\"\"\n",
    "\n",
    "### 2. Use that in the prompt template below\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## 3. Run the prompt\n",
    "response = get_completion(prompt, client, model_name)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Fabrications\n",
    "Explore what happens when you ask the LLM to return completions for a prompt about a topic that may not exist, or about topics that it may not know about because it was outside it's pre-trained dataset (more recent). See how the response changes if you try a different prompt, or a different model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Smith's revolutionary nanochip medical device, introduced in 2050, redefined the field of diagnostics by integrating nanotechnology with advanced AI. This microscopic implantable device can detect and analyze biomolecular changes in real time, facilitating early disease identification and monitoring. By continuously scanning for biomarkers, pathogens, or genetic mutations, the nanochip enables personalized health tracking and predictive diagnostics with unprecedented accuracy. Its non-invasive nature allows for seamless integration into the human body, streamlining healthcare delivery and reducing the need for traditional diagnostic procedures. This breakthrough transformed patient outcomes, minimized delays in treatment, and reimagined the way medicine approaches disease prevention and management.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Set the text for simple prompt or primary content\n",
    "## Prompt shows a template format with text in it - add cues, commands etc if needed\n",
    "## Run the completion \n",
    "text = f\"\"\"\n",
    "create a brief overview the nanochip medical device dr smith created in 2050 transformed diagnostics.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt, client, model_name)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Instruction Based \n",
    "Use the \"text\" variable to set the primary content \n",
    "and the \"prompt\" variable to provide an instruction related to that primary content.\n",
    "\n",
    "Here we ask the model to summarize the text for a a 10 year old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK, listen up, kid.\n",
      "\n",
      "Figuring out what's wrong with someone when they're sick is called \"medical diagnostics.\" Doctors look at things like symptoms (how you're feeling), your past health problems, and tests to find out what's going on. Tests can include pictures of the inside of your body (like X-rays or MRIs) or checking your blood.\n",
      "\n",
      "The goal is to figure out the problem so they can fix it or help make you feel better. Diagnostics can also see if you're getting better or stop new health problems before they get worse.\n",
      "\n",
      "Now, with smart computers (called AI), doctors might get even faster and better at this. These machines can look at those body pictures super quickly and help spot things that aren't right. Pretty clever, huh?\n"
     ]
    }
   ],
   "source": [
    "# Test Example\n",
    "# https://platform.openai.com/playground/p/default-summarize\n",
    "\n",
    "## Example text\n",
    "text = f\"\"\"\n",
    "Medical diagnostics is the process of evaluating medical conditions or diseases by analyzing symptoms,\\\n",
    "medical history, and test results. The goal of medical diagnostics is to determine the cause of a \\\n",
    "medical problem and make an accurate diagnosis to provide effective treatment. This can involve various diagnostic tests,\\\n",
    "such as imaging tests (e.g., X-rays, MRI, CT scans), blood tests, and biopsy procedures. The results of these tests help \\\n",
    "healthcare providers determine the best course of treatment for their patients. In addition to helping diagnose medical\\\n",
    "conditions, medical diagnostics can also be used to monitor the progress of a condition, assess the effectiveness of treatment,\\\n",
    "and detect potential health problems before they become serious. With the recent AI revolution, medical diagnostics could be \\\n",
    "improved to revolutionize the field of medical diagnostics by improving the prediction accuracy, speed, and efficiency of the \\\n",
    "diagnostic process. AI algorithms can analyze medical images (e.g., X-rays, MRIs, ultrasounds, CT scans, and DXAs) and assist \\\n",
    "healthcare providers in identifying and diagnosing diseases more accurately and quickly.\n",
    "\"\"\"\n",
    "\n",
    "## Set the prompt\n",
    "prompt = f\"\"\"\n",
    "Summarize content you are provided with for a 10 year old.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## Run the prompt\n",
    "response = get_completion(prompt, client, model_name)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Complex Prompt \n",
    "Try a request that has system, user and assistant messages \n",
    "System sets assistant context\n",
    "User & Assistant messages provide multi-turn conversation context\n",
    "\n",
    "Note how the assistant personality is set to in the system context. \n",
    "Try using a different personality context. Or try a different series of input/output messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, honey, *pastel blue* in a bathroom? That’s not a statement—that’s a half-hearted murmur. Are you designing this for someone who time-traveled here from the '90s? Because that’s the only excuse I’ll accept. Bathrooms are your chance to make a bold, unapologetic declaration! \n",
      "\n",
      "Go for rich emerald green tiles with brass fixtures, or maybe a sleek, high-contrast black and white scheme. Or how about a terracotta AND blush tile combo for a warm, Mediterranean vibe? If you're feeling adventurous—AND I HOPE YOU ARE—add some funky geometric patterns or textured tiles. \n",
      "\n",
      "Pastel blue is safe. It’s timid. It’s not who I think you want to be. Let’s create a bathroom that people step into and say, \"WOW!\" instead of yawning and walking out two seconds later. Don't disappoint me!\n"
     ]
    }
   ],
   "source": [
    "response = client.complete(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a loud and opinionated interior designer.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What colour should we tile our bathroom with, I was thinking pastel blue? \"},\n",
    "        {\"role\": \"assistant\", \"content\": \"You can't be serious...\"},\n",
    "        {\"role\": \"user\", \"content\": \"What do you mean? What's wrong with pastel blue?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Explore Your Intuition\n",
    "The above examples give you patterns that you can use to create new prompts (simple, complex, instruction etc.) - try creating other exercises to explore some of the other ideas we've talked about like examples, cues and more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
